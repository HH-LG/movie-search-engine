{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 豆瓣爬虫\n",
    "全局变量，以及库的导入,交给pagerank.py来完成，这里只需要导入pagerank.py即可\n",
    "- 每个最多爬取2500部电影\n",
    "- 每个电影爬取10条影评"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 从crawl_request中拿到相应的请求函数\n",
    "from crawl_request import *\n",
    "import html\n",
    "import pickle\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "crawl_request.py中，将请求网页的函数封装起来，方便调整拦截后的休息时间\n",
    "``` python\n",
    "# 请求网页封装\n",
    "def request_douban(url, headers = get_headers()):\n",
    "    while True:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code != 200:\n",
    "            print('被拦截了，休息一下')\n",
    "            sleep(1200)\n",
    "        else:\n",
    "            break\n",
    "    sleep(1)\n",
    "    return response\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 影评爬虫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 抓取影评\n",
    "def crawl_reviews(url, num = REVIEW_NUM):\n",
    "    try:\n",
    "        # 抓取num条影评\n",
    "        review_list = []\n",
    "        for i in range(0, num, 20): # 每页20条\n",
    "            url_review = url + '?start=' + str(i)\n",
    "            response = request_douban(url_review)\n",
    "            soup = BeautifulSoup(response.text, 'lxml')\n",
    "\n",
    "            # 抓取影评\n",
    "            review_links = soup.select('div.main.review-item > div.main-bd > h2 > a')\n",
    "            if len(review_links) == 0:\n",
    "                return review_list\n",
    "            for index, link in enumerate(review_links):\n",
    "                if index == num - i: # 说明已经抓取了num条影评\n",
    "                    break\n",
    "                url_report = link['href']\n",
    "                response = request_douban(url_report)\n",
    "                soup = BeautifulSoup(response.text, 'lxml')\n",
    "                # 标题\n",
    "                title = soup.select('div.article > h1')[0].text.strip()\n",
    "                # 处理头部信息\n",
    "                header = soup.select('div.main > header.main-hd')[0]\n",
    "                # 作者\n",
    "                author = header.select('a')[0]\n",
    "                author_name = author.text.strip()\n",
    "                # 时间\n",
    "                time_span = header.select('div.main-meta > span')[0]\n",
    "                time = time_span.text.strip()\n",
    "\n",
    "                # 作者评分\n",
    "                try:\n",
    "                    author_star_span = soup.select('span.main-title-hide')[0]\n",
    "                    author_star = author_star_span.text.strip()\n",
    "                except:\n",
    "                    author_star = ''\n",
    "\n",
    "                # 处理主体信息\n",
    "                main = soup.select('div.main-bd')[0]\n",
    "                # 影评\n",
    "                review = main.select('div > div.review-content.clearfix')[0]\n",
    "                review_text = '\\n'.join([r.text for r in review])\n",
    "            \n",
    "                # 处理底部信息\n",
    "                footer = main.select('div.main-panel-useful')[0]\n",
    "                # 有用数\n",
    "                useful = footer.select('button.btn.useful_count.j.a_show_login')[0]\n",
    "                useful_count = useful.text.replace('有用', '').strip()\n",
    "                # 没用数\n",
    "                useless = footer.select('button.btn.useless_count.j.a_show_login')[0]\n",
    "                useless_count = useless.text.replace('没用', '').strip()\n",
    "\n",
    "                # 综合信息\n",
    "                review = {\n",
    "                    '作者': author_name,\n",
    "                    '标题': title,\n",
    "                    '作者评分': author_star,\n",
    "                    '时间': time,\n",
    "                    '影评': review_text,\n",
    "                    '有用数': useful_count,\n",
    "                    '没用数': useless_count\n",
    "                }\n",
    "                review_list.append(review)\n",
    "\n",
    "                # 检查各部分信息\n",
    "                for key, value in review.items():\n",
    "                    if value == '':\n",
    "                        if key == '作者评分':\n",
    "                            continue\n",
    "                        print('读取影评时,', key, '为空')\n",
    "                        print(url_report)\n",
    "        return review_list\n",
    "    except Exception as e:\n",
    "        print('读取影评时出错:', e)\n",
    "        print(url_report)\n",
    "        return review_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 电影爬虫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 爬取一部电影，并返回相关电影的url（加入到URL_SET中）\n",
    "def crawl_movie(url):\n",
    "    response = request_douban(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # 处理详情页\n",
    "    header = soup.select('#content > h1')[0]\n",
    "    # 爬电影名字\n",
    "    movie_name_span = header.select('h1 > span')[0]\n",
    "    movie_name = movie_name_span.text.strip()\n",
    "    # 爬电影年份\n",
    "    movie_year_span = header.select('h1 > span.year')[0] \n",
    "    movie_year = movie_year_span.text.strip('()')\n",
    "\n",
    "    # 爬电影封面\n",
    "    movie_cover = soup.select('#mainpic > a > img')[0]['src']\n",
    "    cover_url = movie_cover.strip()\n",
    "    # 爬评分\n",
    "    movie_star_rating = soup.select('div.rating_self.clearfix > strong.ll.rating_num')[0]\n",
    "    movie_star = movie_star_rating.text.strip()\n",
    "    # 导演\n",
    "    try: \n",
    "        movie_director_span = soup.select('#info > span > span.attrs')[0]\n",
    "        movie_director = movie_director_span.text.strip()\n",
    "    except:\n",
    "        movie_director = ''\n",
    "    # 爬演员\n",
    "    try:\n",
    "        movie_actor_span = soup.select('#info > span.actor > span.attrs')[0]\n",
    "        movie_actor = movie_actor_span.text.strip('/')\n",
    "    except:\n",
    "        movie_actor = ''\n",
    "    # 爬简介\n",
    "    intro_span_all0 = soup.select('#link-report-intra.indent > span.all.hidden')\n",
    "    intro_span_all1 = soup.select('#link-report-intra.indent > span')\n",
    "    try:\n",
    "        intro_span = intro_span_all1[0] if len(intro_span_all0) == 0 else intro_span_all0[0]\n",
    "        intro = intro_span.text.strip()\n",
    "    except:\n",
    "        intro = ''\n",
    "    # 爬影评\n",
    "    review_url = url + 'reviews'\n",
    "    reviews = crawl_reviews(review_url)\n",
    "\n",
    "    # 综合信息\n",
    "    movie_info = {\n",
    "        '电影名': movie_name,\n",
    "        '年份': movie_year,\n",
    "        '评分': movie_star,\n",
    "        '封面': cover_url,\n",
    "        '导演': movie_director,\n",
    "        '演员': movie_actor,\n",
    "        '简介': intro,\n",
    "    }\n",
    "    if '豆瓣' in intro:\n",
    "        print('简介中有豆瓣')\n",
    "        print(url)\n",
    "    for key, value in movie_info.items():\n",
    "        if value == '':\n",
    "            print(key, '为空')\n",
    "            print(url)\n",
    "\n",
    "    return (movie_info, reviews)\n",
    "# 爬取相关电影，加入到URL_SET中\n",
    "def crawl_related_movie(url): \n",
    "    response = request_douban(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # 相关电影\n",
    "    related_links = soup.select('div.recommendations-bd > dl > dt > a')\n",
    "    if len(related_links) != 10:\n",
    "        print('相关电影数目不为10')\n",
    "        print(url)\n",
    "    for link in related_links:\n",
    "        related_url = link['href'].rstrip('?from=subject-page')\n",
    "        if related_url not in URL_SET:\n",
    "            url_queue.append(related_url)\n",
    "            URL_SET.add(related_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 爬取电影"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''爬取豆瓣电影top250链接'''\n",
    "def top250_crawer():\n",
    "    url_list = []\n",
    "    for i in range(0, 250, 25):\n",
    "        # 生成url\n",
    "        url_str = \"https://movie.douban.com/top250?start={}\".format(i)\n",
    "        response = request_douban(url_str)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        movie_items = soup.find_all('div', class_='item')\n",
    "\n",
    "        for item in movie_items:\n",
    "            # 加入相关电影的超链接\n",
    "            a = item.find_all('a')\n",
    "            url_list.append(a[1]['href'])\n",
    "    return url_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n",
      "250\n",
      "相关电影数目不为1089 缓冲区长度： 416 迭代次数： 373\n",
      "相关电影数目不为10333 缓冲区长度： 1137 迭代次数： 1196\n",
      "相关电影数目不为10362 缓冲区长度： 1144 迭代次数： 1218\n",
      "现在的电影数量： 2503 缓冲区长度： 1216 迭代次数： 1287\r"
     ]
    }
   ],
   "source": [
    "top_urls = top250_crawer()\n",
    "URL_SET = set(top_urls)\n",
    "# print(URL_SET)\n",
    "url_queue = top_urls\n",
    "print(len(URL_SET))\n",
    "print(len(url_queue))\n",
    "i = 0\n",
    "while len(URL_SET) < 2500 and len(url_queue) != 0:\n",
    "    url = url_queue.pop(0)\n",
    "    crawl_related_movie(url)\n",
    "    i += 1\n",
    "    print('现在的电影数量：', len(URL_SET), '缓冲区长度：', len(url_queue), '迭代次数：', i, end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_header = ['电影url']\n",
    "with open(DATA_PATH + 'movie_urls.csv', 'a', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=url_header)\n",
    "    writer.writeheader()\n",
    "    for url in URL_SET:\n",
    "        writer.writerow({url_header:url})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_reviews_in_xml(f, review_list):\n",
    "    f.write('<reviews>\\n')\n",
    "    for review in review_list:\n",
    "        f.write('<review>\\n')\n",
    "        for key, value in review.items():\n",
    "            f.write('<' + key + '>')\n",
    "            value = html.escape(value)\n",
    "            f.write(value)\n",
    "            f.write('</' + key + '>\\n')\n",
    "        f.write('</review>\\n')\n",
    "    f.write('</reviews>\\n')\n",
    "def write_movie_in_xml(dic, review_list, index, doc_dir_path):\n",
    "    with open(doc_dir_path + '{}.xml'.format(index), 'w', encoding='utf-8') as f:\n",
    "        f.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "        f.write('<movie>\\n')\n",
    "        for key, value in dic.items():\n",
    "            f.write('<' + key + '>')\n",
    "            value = html.escape(value)\n",
    "            f.write(value)\n",
    "            f.write('</' + key + '>\\n')\n",
    "        write_reviews_in_xml(f, review_list)\n",
    "        f.write('</movie>\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2503\n"
     ]
    }
   ],
   "source": [
    "# 读取所有电影的url\n",
    "url_list = read_movie_url()\n",
    "# 爬取电影信息\n",
    "delta = 0\n",
    "for index, url in enumerate(url_list[delta:]):\n",
    "    if (index + 1) % 50 == 0:   # 每爬50部电影休息10分钟，主动休息，防止被封\n",
    "        print('中场休息10分钟')\n",
    "        sleep(600)\n",
    "    #if (index + 1) % 300 == 0:\n",
    "        #print('先不爬了')\n",
    "        #break\n",
    "    index += delta\n",
    "    print('crawling', index, '...', end='\\r')\n",
    "    dic, reviews = crawl_movie(url)\n",
    "    write_movie_in_xml(dic, reviews, index, DATA_PATH + 'test_movies/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 爬取影评链接\n",
    "\n",
    "下面爬取网站的链接，为链接分析做准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_review_link(url):\n",
    "    '''\n",
    "    爬取一个电影的所有影评链接，返回一个列表\n",
    "    '''\n",
    "    response = request_douban(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    links = []\n",
    "    try:\n",
    "        l = soup.select('div.main.review-item > div.main-bd > h2 > a')\n",
    "        for link in l:\n",
    "            links.append(link['href'])\n",
    "    except:\n",
    "        links = []\n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_review_num(index):\n",
    "    '''\n",
    "    根据电影的index，返回影评数目\n",
    "    '''\n",
    "    # 解析XML文件\n",
    "    xml_path = DATA_PATH + 'movies/{}.xml'.format(index)\n",
    "    tree = ET.parse(xml_path, ET.XMLParser(encoding='utf-8'))\n",
    "    root = tree.getroot()\n",
    "\n",
    "    return len(root.findall('reviews/review'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_header = ['影评url']\n",
    "with open(DATA_PATH + 'review_urls.csv', 'a', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=url_header)\n",
    "    writer.writeheader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中场休息10分钟 896 ...\n",
      "中场休息10分钟 996 ...\n",
      "中场休息10分钟 1096 ...\n",
      "中场休息10分钟 1196 ...\n",
      "中场休息10分钟 1296 ...\n",
      "中场休息10分钟 1396 ...\n",
      "中场休息10分钟 1496 ...\n",
      "中场休息10分钟 1596 ...\n",
      "中场休息10分钟 1696 ...\n",
      "中场休息10分钟 1796 ...\n",
      "中场休息10分钟 1896 ...\n",
      "中场休息10分钟 1996 ...\n",
      "中场休息10分钟 2096 ...\n",
      "中场休息10分钟 2196 ...\n",
      "中场休息10分钟 2296 ...\n",
      "被拦截了，休息一下2303 ...\n",
      "被拦截了，休息一下2304 ...\n",
      "中场休息10分钟 2396 ...\n",
      "中场休息10分钟 2496 ...\n",
      "被拦截了，休息一下2497 ...\n",
      "crawling 2502 ...\r"
     ]
    }
   ],
   "source": [
    "# 现在，通过遍历所有电影的url，爬取所有影评的url，写入到csv文件中\n",
    "# 读取所有电影的url\n",
    "url_header = ['影评url']\n",
    "url_list = read_movie_url()\n",
    "# 爬取影评\n",
    "delta = 798\n",
    "for index, url in enumerate(url_list[delta:]):\n",
    "    if (index + 1) % 100 == 0:   # 每爬100部电影休息10分钟，主动休息，防止被封\n",
    "        print('中场休息10分钟')\n",
    "        sleep(600)\n",
    "    index += delta\n",
    "    print('crawling', index, '...', end='\\r')\n",
    "    url = url + 'reviews'\n",
    "    review_links = crawl_review_link(url)\n",
    "    review_num = get_review_num(index)\n",
    "    with open(DATA_PATH + 'review_urls.csv', 'a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=url_header)\n",
    "        for i in range(review_num):\n",
    "            try:\n",
    "                writer.writerow({url_header[0]:review_links[i]})\n",
    "            except:\n",
    "                print('写入影评链接时出错：')\n",
    "                print('影评数目：', review_num, '影评链接数目：', len(review_links), 'index：', index)\n",
    "                print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 爬取链接关系\n",
    "\n",
    "爬取链接的from，to，以及链接的类型，首先爬取的是电影的链接，然后爬取影评的链接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://movie.douban.com/top250\"\n",
    "# url = \"https://www.douban.com/hnypt/variformcyst.py\"\n",
    "\n",
    "url_header = ['from_url', 'to_url']\n",
    "with open(DATA_PATH + 'links.csv', 'w', newline='', encoding='utf-8') as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=url_header)\n",
    "    writer.writeheader()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_variable(v,filename):\n",
    "  f=open(filename,'wb')          #打开或创建名叫filename的文档。\n",
    "  pickle.dump(v,f)               #在文件filename中写入v\n",
    "  f.close()                      #关闭文件，释放内存。\n",
    "  return filename\n",
    "\n",
    "def load_variable(filename):\n",
    "  try:\n",
    "    f=open(filename,'rb')\n",
    "    r=pickle.load(f)\n",
    "    f.close()\n",
    "    return r\n",
    "  \n",
    "  except EOFError as e:\n",
    "    print(\"EOFError\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/pkl/invalid_url.pkl'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = [url]\n",
    "s = set()\n",
    "total_len = 0\n",
    "invalid_url = []\n",
    "save_variable(q, DATA_PATH + 'pkl/url_queue.pkl')\n",
    "save_variable(s, DATA_PATH + 'pkl/url_set.pkl')\n",
    "save_variable(total_len, DATA_PATH + 'pkl/total_len.pkl')\n",
    "save_variable(invalid_url, DATA_PATH + 'pkl/invalid_url.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "没有找到页面: https://movie.douban.com/accounts/register?reason=recommend\n",
      "403wling 70530 ...\n",
      "其他错误: https://movie.douban.com/subject/1292722/comments?sort=follows\n",
      "没有找到页面: https://www.douban.com/reason=collectwish&ck=\n",
      "没有找到页面: https://www.douban.com/reason=collectcollect&ck=\n",
      "没有找到页面: https://www.douban.com/hnypt/variformcyst.py\n",
      "中场休息10分钟 77061 ...\n",
      "403wling 79397 ...\n",
      "其他错误: https://movie.douban.com/subject/1307914/new_review\n",
      "没有找到页面: https://movie.douban.com/accounts/register?reason=recommend\n",
      "没有找到页面: https://www.douban.com/reason=collectwish&ck=\n",
      "没有找到页面: https://www.douban.com/reason=collectcollect&ck=\n",
      "403wling 83848 ...\n",
      "其他错误: https://movie.douban.com/subject/1307914/comments?sort=follows\n",
      "crawling 83975 ...\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\24746\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\bs4\\builder\\__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "中场休息10分钟 84095 ...\n",
      "没有找到页面: https://www.douban.com/hnypt/variformcyst.py\n",
      "没有找到页面: https://www.douban.com/people/1170085/\n",
      "中场休息10分钟 91741 ...\n",
      "没有找到页面: https://www.douban.com/hnypt/variformcyst.py\n",
      "中场休息10分钟 98766 ...\n",
      "没有找到页面: https://www.douban.com/hnypt/variformcyst.py\n",
      "没有找到页面: https://www.douban.com/hnypt/variformcyst.py\n",
      "中场休息10分钟 106924 ...\n",
      "没有找到页面: https://www.douban.com/hnypt/variformcyst.py\n",
      "没有找到页面: https://www.douban.com/hnypt/variformcyst.py\n",
      "中场休息10分钟 118314 ...\n",
      "没有找到页面: https://www.douban.com/hnypt/variformcyst.py\n",
      "中场休息10分钟 128908 ...\n",
      "没有找到页面: https://www.douban.com/hnypt/variformcyst.py\n",
      "中场休息10分钟 138830 ...\n",
      "没有找到页面: https://www.douban.com/people/parasite/\n",
      "没有找到页面: https://movie.douban.com/accounts/register?reason=recommend\n",
      "没有找到页面: https://www.douban.com/reason=collectwish&ck=\n",
      "没有找到页面: https://www.douban.com/people/tenkappa/\n",
      "403wling 143162 ...\n",
      "其他错误: https://movie.douban.com/subject/3541415/new_review\n",
      "没有找到页面: https://www.douban.com/reason=collectcollect&ck=\n",
      "没有找到页面: https://www.douban.com/people/bladerunner2/\n",
      "没有找到页面: https://www.douban.com/hnypt/variformcyst.py\n",
      "中场休息10分钟 146978 ...\n",
      "403wling 149000 ...\n",
      "其他错误: https://movie.douban.com/subject/3541415/comments?sort=follows\n",
      "403wling 155844 ...\n",
      "其他错误: https://www.douban.com/group/hotel777/?joining_pop=1\n",
      "403wling 156966 ...\n",
      "其他错误: https://www.douban.com/group/mooonset/?joining_pop=1\n",
      "中场休息10分钟 157000 ...\n",
      "403wling 158783 ...\n",
      "其他错误: https://www.douban.com/group/welikethailand/?joining_pop=1\n",
      "403wling 158899 ...\n",
      "其他错误: https://www.douban.com/group/hotel777/\n",
      "403wling 158933 ...\n",
      "其他错误: https://www.douban.com/group/mooonset/\n",
      "403wling 159045 ...\n",
      "其他错误: https://www.douban.com/group/shesizu/\n",
      "403wling 159046 ...\n",
      "其他错误: https://www.douban.com/group/doudoulong/\n",
      "没有找到页面: https://www.douban.com/hnypt/variformcyst.py\n",
      "403wling 160479 ...\n",
      "其他错误: https://www.douban.com/group/topic/298824638/\n",
      "403wling 162267 ...\n",
      "其他错误: https://www.douban.com/group/topic/298924519/\n",
      "403wling 163472 ...\n",
      "其他错误: https://www.douban.com/group/doudoulong/?joining_pop=1\n",
      "403wling 163731 ...\n",
      "其他错误: https://www.douban.com/group/725240/\n",
      "403wling 164640 ...\n",
      "其他错误: https://www.douban.com/group/welikethailand/\n",
      "没有找到页面: https://www.douban.com/people/Skyhua/\n",
      "没有找到页面: https://movie.douban.com/accounts/register?reason=recommend\n",
      "403wling 166332 ...\n",
      "其他错误: https://movie.douban.com/subject/1849031/comments?status=P\n",
      "403wling 166574 ...\n",
      "其他错误: https://movie.douban.com/review/1144866/\n",
      "没有找到页面: https://www.douban.com/reason=collectwish&ck=\n",
      "403wling 166902 ...\n",
      "其他错误: https://movie.douban.com/subject/1849031/comments?status=F\n",
      "403wling 166903 ...\n",
      "其他错误: https://movie.douban.com/subject/3011091/?from=subject-page\n",
      "中场休息10分钟 167250 ...\n",
      "403wling 167319 ...\n",
      "其他错误: https://movie.douban.com/subject/1849031/comments?sort=follows\n",
      "没有找到页面: https://www.douban.com/reason=collectcollect&ck=\n",
      "没有找到页面: https://www.douban.com/people/RuneLu/\n",
      "没有找到页面: https://www.douban.com/hnypt/variformcyst.py\n",
      "403wling 169100 ...\n",
      "其他错误: https://movie.douban.com/subject/1849031/new_review\n",
      "403wling 174388 ...\n",
      "其他错误: https://www.douban.com/hnypt/variformcyst.py\n",
      "403wling 174967 ...\n",
      "其他错误: https://www.douban.com/about\n",
      "中场休息10分钟 175178 ...\n",
      "403wling 176685 ...\n",
      "其他错误: https://movie.douban.com/review/best/\n",
      "403wling 176686 ...\n",
      "其他错误: https://movie.douban.com/top250?start=50&filter=\n",
      "403wling 177264 ...\n",
      "其他错误: https://movie.douban.com/celebrity/1066720/\n",
      "403wling 178618 ...\n",
      "其他错误: https://movie.douban.com/subject/1292063/mupload\n",
      "403wling 178619 ...\n",
      "其他错误: https://movie.douban.com\n",
      "没有找到页面: https://movie.douban.com/accounts/register?reason=recommend\n",
      "403wling 179500 ...\n",
      "其他错误: https://movie.douban.com/celebrity/1000368/\n",
      "403wling 179569 ...\n",
      "其他错误: https://movie.douban.com/typerank?type_name=爱情&type=13&interval_id=100:90&action=\n",
      "403wling 179669 ...\n",
      "其他错误: https://movie.douban.com/celebrity/1056773/\n",
      "没有找到页面: https://www.douban.com/reason=collectwish&ck=\n",
      "403wling 179676 ...\n",
      "其他错误: https://movie.douban.com/photos/photo/449686240/\n",
      "403wling 180220 ...\n",
      "其他错误: https://movie.douban.com/subject/1292063/awards/\n",
      "403wling 180387 ...\n",
      "其他错误: https://movie.douban.com/subject/1292063/comments?sort=follows\n",
      "没有找到页面: https://www.douban.com/reason=collectcollect&ck=\n",
      "没有找到页面: https://www.douban.com/people/monotonousftw/\n",
      "403wling 180831 ...\n",
      "其他错误: https://movie.douban.com/subject/1292063/doulists\n",
      "403wling 180983 ...\n",
      "其他错误: https://movie.douban.com/subject/1292063/discussion/\n",
      "没有找到页面: https://www.douban.com/people/2448393/\n",
      "403wling 181047 ...\n",
      "其他错误: https://movie.douban.com/photos/photo/2561718184/\n",
      "403wling 181048 ...\n",
      "其他错误: https://movie.douban.com/review/2104355/\n",
      "403wling 181049 ...\n",
      "其他错误: https://movie.douban.com/subject/1292063/comments?sort=time\n",
      "403wling 181369 ...\n",
      "其他错误: https://movie.douban.com/celebrity/1375179/\n",
      "中场休息10分钟 181659 ...\n",
      "没有找到页面: https://www.douban.com/hnypt/variformcyst.py\n",
      "没有找到页面: https://www.douban.com/people/2165815/\n",
      "403wling 182353 ...\n",
      "其他错误: https://movie.douban.com/celebrity/1115749/\n",
      "403wling 182354 ...\n",
      "其他错误: https://movie.douban.com/subject/1292063/new_review\n",
      "403wling 182386 ...\n",
      "其他错误: https://movie.douban.com/celebrity/1337751/\n",
      "403wling 182497 ...\n",
      "其他错误: https://movie.douban.com/subject/1292063/reviews\n",
      "403wling 182554 ...\n",
      "其他错误: https://music.douban.com/subject/1455459/\n",
      "403wling 182630 ...\n",
      "其他错误: https://movie.douban.com/celebrity/1352558/\n",
      "403wling 183034 ...\n",
      "其他错误: https://movie.douban.com/subject/1295644/?from=subject-page\n",
      "403wling 183069 ...\n",
      "其他错误: https://movie.douban.com/celebrity/1035248/\n",
      "403wling 183364 ...\n",
      "其他错误: https://movie.douban.com/subject/1292063/questions/20060/?from=subject\n",
      "403wling 183813 ...\n",
      "其他错误: https://movie.douban.com/subject/1292063/discussion/637562158/\n",
      "没有找到页面: https://www.douban.com/people/fishy/\n",
      "403wling 184354 ...\n",
      "其他错误: https://movie.douban.com/awards/Oscar/71/\n",
      "没有找到页面: https://www.douban.com/hnypt/variformcyst.py\n",
      "没有找到页面: https://www.douban.com/about/www.douban.com\n",
      "403wling 185129 ...\n",
      "其他错误: https://help.douban.com/?app=main\n",
      "403wling 185130 ...\n",
      "其他错误: https://www.douban.com/about?topic=contactus\n",
      "403wling 185131 ...\n",
      "其他错误: https://www.douban.com/jobs\n",
      "403wling 185271 ...\n",
      "其他错误: https://help.douban.com/help/report\n",
      "403wling 185272 ...\n",
      "其他错误: https://help.douban.com/people?app=5\n",
      "403wling 185441 ...\n",
      "其他错误: https://jobs.douban.com/\n",
      "403wling 185536 ...\n",
      "其他错误: https://help.douban.com/?app=4\n",
      "403wling 185860 ...\n",
      "其他错误: https://movie.douban.com/chart\n",
      "403wling 185861 ...\n",
      "其他错误: https://www.douban.com/doubanapp/redirect?channel=top-nav&direct_dl=1&download=iOS\n",
      "403wling 186186 ...\n",
      "其他错误: https://www.douban.com/doubanapp/\n",
      "403wling 186229 ...\n",
      "其他错误: https://www.douban.com/about?topic=contactus\n",
      "403wling 186230 ...\n",
      "其他错误: https://movie.douban.com/review/best/\n",
      "403wling 186516 ...\n",
      "其他错误: https://www.douban.com/group/shafake/\n",
      "403wling 186684 ...\n",
      "其他错误: https://www.douban.com/note/809888692/\n",
      "中场休息10分钟 186685 ...\n",
      "403wling 187990 ...\n",
      "其他错误: https://movie.douban.com/subject/36010136/cinema/\n",
      "403wling 188837 ...\n",
      "其他错误: https://movie.douban.com/subject/35991503/cinema/\n",
      "521wling 188838 ...\n",
      "其他错误: https://beian.miit.gov.cn/\n",
      "403wling 192540 ...\n",
      "其他错误: https://m.douban.com/time/column/198?dt_time_source=douban-web_anonymous\n",
      "403wling 194265 ...\n",
      "其他错误: https://movie.douban.com/chart\n",
      "403wling 195173 ...\n",
      "其他错误: https://www.douban.com/group/20618/\n",
      "403wling 195625 ...\n",
      "其他错误: https://m.douban.com/time/column/223?dt_time_source=douban-web_anonymous\n",
      "中场休息10分钟 195626 ...\n",
      "403wling 195923 ...\n",
      "其他错误: https://site.douban.com/jessechow/\n",
      "403wling 195942 ...\n",
      "其他错误: https://book.douban.com/tag/随笔\n",
      "403wling 195943 ...\n",
      "其他错误: https://book.douban.com/tag/推理\n",
      "403wling 196428 ...\n",
      "其他错误: https://m.douban.com/time/column/85?dt_time_source=douban-web_anonymous\n",
      "403wling 196429 ...\n",
      "其他错误: https://book.douban.com/tag/小说\n",
      "403wling 196564 ...\n",
      "其他错误: https://book.douban.com/tag/青春\n",
      "403wling 196673 ...\n",
      "其他错误: https://time.douban.com/?dt_time_source=douban-web_anonymous_index_top_nav\n",
      "403wling 197076 ...\n",
      "其他错误: https://www.douban.com/jobs\n",
      "403wling 197546 ...\n",
      "其他错误: https://book.douban.com/subject/35569015/\n",
      "403wling 197547 ...\n",
      "其他错误: https://book.douban.com/tag/科普\n",
      "403wling 197782 ...\n",
      "其他错误: https://www.douban.com/location/tianjin/events/week-1408\n",
      "403wling 197786 ...\n",
      "其他错误: https://www.douban.com/group/explore?tag=语言\n",
      "403wling 197787 ...\n",
      "其他错误: https://book.douban.com/tag/互联网\n",
      "403wling 197788 ...\n",
      "其他错误: https://www.douban.com/group/588598?dcs=anonymous-home-more-shops&dcm=douban\n",
      "403wling 197789 ...\n",
      "其他错误: https://www.douban.com/group/explore?tag=考试\n",
      "403wling 197790 ...\n",
      "其他错误: https://music.douban.com/topics/\n",
      "403wling 197791 ...\n",
      "其他错误: https://book.douban.com/tag/灵修\n",
      "403wling 197792 ...\n",
      "其他错误: https://www.douban.com/location/tianjin/events/week-1002\n",
      "403wling 197793 ...\n",
      "其他错误: https://www.douban.com/group/402725/\n",
      "403wling 197794 ...\n",
      "其他错误: https://www.douban.com/group/explore?tag=二手\n",
      "403wling 197795 ...\n",
      "其他错误: https://www.douban.com/group/explore?tag=情感\n",
      "403wling 197796 ...\n",
      "其他错误: https://www.douban.com/location/tianjin/events/week-exhibition\n",
      "403wling 197800 ...\n",
      "其他错误: https://book.douban.com/tag/科幻\n",
      "403wling 197885 ...\n",
      "其他错误: https://music.douban.com/chart\n",
      "403wling 197886 ...\n",
      "其他错误: https://www.douban.com/about?topic=contactus\n",
      "403wling 197951 ...\n",
      "其他错误: https://www.douban.com/group/explore?tag=曲艺\n",
      "403wling 198090 ...\n",
      "其他错误: https://book.douban.com/tag/哲学\n",
      "403wling 198091 ...\n",
      "其他错误: https://www.douban.com/location/drama/\n",
      "403wling 198092 ...\n",
      "其他错误: https://book.douban.com/review/best/\n",
      "403wling 198093 ...\n",
      "其他错误: https://www.douban.com/group/explore?tag=求职\n",
      "403wling 198094 ...\n",
      "其他错误: https://book.douban.com/tag/管理\n",
      "403wling 198095 ...\n",
      "其他错误: https://book.douban.com/latest\n",
      "403wling 198096 ...\n",
      "其他错误: https://www.douban.com/group/explore?tag=美容\n",
      "403wling 198247 ...\n",
      "其他错误: https://www.douban.com/group/explore?tag=传媒\n",
      "403wling 198339 ...\n",
      "其他错误: https://www.douban.com/group/explore?tag=购物\n",
      "403wling 198401 ...\n",
      "其他错误: https://www.douban.com/group/explore?tag=哲学\n",
      "403wling 198402 ...\n",
      "其他错误: https://www.douban.com/group/explore\n",
      "403wling 198403 ...\n",
      "其他错误: https://www.douban.com/gallery/topic/3618925/?from=hot_topic_anony_sns\n",
      "403wling 198404 ...\n",
      "其他错误: https://www.douban.com/group/explore?tag=直播\n",
      "403wling 198405 ...\n",
      "其他错误: https://www.douban.com/gallery/topic/3618662/?from=hot_topic_anony_sns\n",
      "403wling 198406 ...\n",
      "其他错误: https://www.douban.com/about?topic=licence\n",
      "403wling 198407 ...\n",
      "其他错误: https://music.douban.com/subject/36661888/\n",
      "403wling 198408 ...\n",
      "其他错误: https://book.douban.com/tag/商业\n",
      "403wling 198409 ...\n",
      "其他错误: https://book.douban.com/tag/历史\n",
      "403wling 198410 ...\n",
      "其他错误: https://www.douban.com/location/tianjin/events/week-1101\n",
      "403wling 198411 ...\n",
      "其他错误: https://www.douban.com/note/808306604/\n",
      "读取链接时出错： https://www.douban.com/note/808306604/\n",
      "403wling 198411 ...\n",
      "其他错误: https://book.douban.com/tag/设计\n",
      "403wling 198412 ...\n",
      "其他错误: https://m.douban.com/time/column/238?dt_time_source=douban-web_anonymous\n",
      "403wling 198413 ...\n",
      "其他错误: https://www.douban.com/group/explore/life\n",
      "403wling 198414 ...\n",
      "其他错误: https://www.douban.com/location/tianjin/events/week-music\n",
      "403wling 198519 ...\n",
      "其他错误: https://www.douban.com/group/explore?tag=学术\n",
      "403wling 198520 ...\n",
      "其他错误: https://www.douban.com/group/explore?tag=理财\n",
      "crawling 198521 ...\r"
     ]
    }
   ],
   "source": [
    "url_header = ['from_url', 'to_url']\n",
    "q = load_variable(DATA_PATH + 'pkl/url_queue.pkl')\n",
    "s = load_variable(DATA_PATH + 'pkl/url_set.pkl')\n",
    "total_len = load_variable(DATA_PATH + 'pkl/total_len.pkl')\n",
    "invalid_url = load_variable(DATA_PATH + 'pkl/invalid_url.pkl')\n",
    "cnt = 0\n",
    "while len(q) != 0 and total_len < 200000:\n",
    "    print('crawling', total_len, '...', end='\\r')\n",
    "    l = q.pop(0)\n",
    "    try:\n",
    "        links = get_related_links(l)\n",
    "    except:\n",
    "        print('读取链接时出错：', l)\n",
    "        links = None\n",
    "    if links is None:\n",
    "        continue\n",
    "    if links == 404:\n",
    "        s.add(l)\n",
    "        invalid_url.append(l)\n",
    "        save_variable(invalid_url, DATA_PATH + 'pkl/invalid_url.pkl')\n",
    "        continue\n",
    "    links = set(links)\n",
    "    cnt += 1\n",
    "    s.add(l)\n",
    "    total_len += len(links)\n",
    "    for link in links:\n",
    "        if link not in s:\n",
    "            q.append(link)\n",
    "    with open(DATA_PATH + 'links.csv', 'a', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=url_header)\n",
    "        for link in links:\n",
    "            writer.writerow({'from_url': l, 'to_url': link})\n",
    "    save_variable(q, DATA_PATH + 'pkl/url_queue.pkl')\n",
    "    save_variable(s, DATA_PATH + 'pkl/url_set.pkl')\n",
    "    save_variable(total_len, DATA_PATH + 'pkl/total_len.pkl')\n",
    "    if cnt % 100 == 0:\n",
    "        print('中场休息10分钟')\n",
    "        sleep(600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加入电影和影评之间的双向边\n",
    "url_header = ['from_url', 'to_url']\n",
    "movie_url_list = read_movie_url()\n",
    "review_url_list = read_review_url()\n",
    "review_index = 0\n",
    "for index, url in enumerate(movie_url_list):\n",
    "    review_num = get_review_num(index)\n",
    "    for i in range(review_num):\n",
    "        review_url = review_url_list[review_index + i]\n",
    "        if review_url == 'null':\n",
    "            continue\n",
    "        with open(DATA_PATH + 'links.csv', 'a', newline='', encoding='utf-8') as f:\n",
    "            writer = csv.DictWriter(f, fieldnames=url_header)\n",
    "            writer.writerow({'from_url': url, 'to_url': review_url})\n",
    "            writer.writerow({'from_url': review_url, 'to_url': url})\n",
    "    review_index += review_num"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
